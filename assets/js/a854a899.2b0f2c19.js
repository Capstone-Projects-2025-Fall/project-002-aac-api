"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[3374],{28453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>a});var s=i(96540);const n={},o=s.createContext(n);function r(e){const t=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),s.createElement(o.Provider,{value:t},e.children)}},35192:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"requirements/system-overview","title":"System Overview","description":"Project Abstract","source":"@site/docs/requirements/system-overview.md","sourceDirName":"requirements","slug":"/requirements/system-overview","permalink":"/project-002-aac-api/docs/requirements/system-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-002-aac-api/edit/main/documentation/docs/requirements/system-overview.md","tags":[],"version":"current","lastUpdatedBy":"Giovanni Muniz","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Requirements Specification","permalink":"/project-002-aac-api/docs/category/requirements-specification"},"next":{"title":"System Block Diagram","permalink":"/project-002-aac-api/docs/requirements/system-block-diagram"}}');var n=i(74848),o=i(28453);const r={sidebar_position:1},a="System Overview",c={},d=[{value:"Project Abstract",id:"project-abstract",level:2},{value:"Conceptual Design",id:"conceptual-design",level:2},{value:"Background",id:"background",level:2}];function l(e){const t={h1:"h1",h2:"h2",header:"header",p:"p",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"system-overview",children:"System Overview"})}),"\n",(0,n.jsx)(t.h2,{id:"project-abstract",children:"Project Abstract"}),"\n",(0,n.jsx)(t.p,{children:"This API allows developers to more easily connect their games to audio-to-text programs, allowing them to control the game with an AAC input. On playback the API will run an audio-to-text program and check if the produced text matches possible inputs in the connected game and execute them."}),"\n",(0,n.jsx)(t.h2,{id:"conceptual-design",children:"Conceptual Design"}),"\n",(0,n.jsx)(t.p,{children:"The API will process audio outputs from AAC devices, translate them into game commands, and communicate those commands with games that are built in JavaScript. The API will use Node.js and Python for audio processing and machine learning. The API is modular, as developers can design audio-controlled games wihout handling AAC board input and enable in-game actions."}),"\n",(0,n.jsx)(t.h2,{id:"background",children:"Background"}),"\n",(0,n.jsx)(t.p,{children:"The AAC API will be implemented by game developers looking to support voice input, specifically from the devices of AAC users. The API will access the system microphone, perform speech-to-text, and then return input to the game logic. Developers can define the words that the API will recognize."}),"\n",(0,n.jsx)(t.p,{children:"Currently, there are a few AAC tools and assitive systems that support communication and accesibility with AAC devices, such as Microsoft's Xbox Adapative Controller, which is a controller desgined to offer creative input methods for those who are disabled and other software that uses eye-tracking as inputs with users with congnitive or physical disabilityes, but none use the AAC devices to act as game controllers, and more specifially with audio inputs."})]})}function u(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}}}]);